{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING GOOGLE EARTH PRO IMAGES FOR COLOMBIAN PÁRAMOS\n",
    "\n",
    "In this notebook we will preprocess Google Earth Pro images for different Colombian páramos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import os\n",
    "import boto3\n",
    "import sys\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "print(\"Region = {}\".format(region))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import S3 bucket data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "\n",
    "bucket_name = 'bucket-name'\n",
    "\n",
    "def download_s3_folders(bucket_name, prefixes):\n",
    "    bucket = s3.Bucket(bucket_name)\n",
    "    for prefix in prefixes:\n",
    "        for obj in bucket.objects.filter(Prefix=prefix):\n",
    "            destination_path = os.path.join('..', obj.key)\n",
    "            if not os.path.exists(os.path.dirname(destination_path)):\n",
    "                os.makedirs(os.path.dirname(destination_path))\n",
    "            bucket.download_file(obj.key, destination_path)\n",
    "\n",
    "download_s3_folders(bucket_name, ['config/', 'data/', 'packages/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "import packages.utils.get_path as path\n",
    "import config.constants as const\n",
    "ABSOLUTE_PATH = path.make_path()\n",
    "INTERMEDIATE_DIR = path.make_path(ABSOLUTE_PATH , const.DATA_DIR,const.INTERMEDIATE_DIR)\n",
    "RAW_IMAGES_DIR = path.make_path(ABSOLUTE_PATH , const.DATA_DIR,const.RAW_DIR, const.IMAGES_DIR)\n",
    "NORMALIZED_IMAGES_DIR = path.make_path(ABSOLUTE_PATH , const.DATA_DIR,const.RAW_DIR, const.NORMALIZATION_DIR_IMAGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color and Contrast Correction:\n",
    "Normalizing Brightness and Contrast for Consistent Illumination and Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def calculate_average_brightness_contrast(image_list):\n",
    "    brightness_values = []\n",
    "    contrast_values = []\n",
    "\n",
    "    for image_path in image_list:\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if image is None:\n",
    "            print(f\"Failed to load image: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        # Calculate brightness as the average pixel value\n",
    "        brightness = np.average(image)\n",
    "        brightness_values.append(brightness)\n",
    "\n",
    "        # Calculate contrast as the interquartile range of pixel values\n",
    "        contrast = np.percentile(image, 75) - np.percentile(image, 25)\n",
    "        contrast_values.append(contrast)\n",
    "\n",
    "    # Calculate the average brightness and contrast\n",
    "    average_brightness = np.average(brightness_values)\n",
    "    average_contrast = np.average(contrast_values)\n",
    "\n",
    "    return average_brightness, average_contrast\n",
    "\n",
    "imgesbrutas = path.make_item_list(RAW_IMAGES_DIR)\n",
    "# Use the function\n",
    "average_brightness, average_contrast = calculate_average_brightness_contrast(imgesbrutas)\n",
    "\n",
    "normalized_path = path.make_path(ABSOLUTE_PATH, const.DATA_DIR, const.PROCESSED_DIR, const.NORMALIZATION_DIR)\n",
    "normalized_img_path = path.make_path(ABSOLUTE_PATH, const.DATA_DIR, const.RAW_DIR, const.NORMALIZATION_DIR_IMAGES)\n",
    "np.save(\"{}/{}\".format(normalized_path, const.AVG_BRIGTHNESS), average_brightness)\n",
    "np.save(\"{}/{}\".format(normalized_path, const.AVG_CONTRAST), average_contrast)\n",
    "\n",
    "print(f\"Average brightness: {average_brightness}\")\n",
    "print(f\"Average contrast: {average_contrast}\")\n",
    "\n",
    "\n",
    "def normalize_with_brightness_contrast(image_list, average_brightness, average_contrast):\n",
    "    for image_path in image_list:\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if image is None:\n",
    "            print(f\"Failed to load image: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        # Limit contrast to avoid loss of detail\n",
    "        #average_contrast = np.clip(average_contrast, 0.5, 1.5)\n",
    "\n",
    "        # Normalize the image using the average brightness and contrast\n",
    "        normalized_image = np.clip((image - np.average(image)) * (average_contrast / np.std(image)) + average_brightness, 0, 255).astype(np.uint8)\n",
    "\n",
    "        # Save the normalized image\n",
    "        normalized_image_path = image_path.replace(RAW_IMAGES_DIR, \"{}\".format(normalized_img_path))\n",
    "        print(f\"Saving normalized image to: {normalized_image_path}\")\n",
    "        cv2.imwrite(normalized_image_path, normalized_image)\n",
    "\n",
    "normalize_with_brightness_contrast(imgesbrutas, average_brightness, average_contrast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation:\n",
    "\n",
    "We will use scripts from the [Data Augmentation](../scripts/aumentation.py) notebook to augment the images. We rotate the images by 90, 180 and 270 degrees, and flip them horizontally and vertically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "subprocess.call([\"python\", \"../scripts/aumentation.py\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data Images\n",
    "\n",
    "We will split the images in subimages of 256x256 pixels to train the model. refer to the [Split Images](../scripts/split.py) notebook to split the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "subprocess.call([\"python\", \"../scripts/split.py\", \"--augment_data\", \"False\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_folders = path.make_directories_list(INTERMEDIATE_DIR)\n",
    "\n",
    "normalized_folders = [x for x in img_folders if const.IMAGE_LABEL_END not in x ]\n",
    "normalized_labels_folders = [x for x in img_folders if const.IMAGE_LABEL_END in x]\n",
    "\n",
    "print(f\"Total folders: {len(normalized_labels_folders)*2}\")\n",
    "\n",
    "label_paths = []\n",
    "for label in normalized_labels_folders:\n",
    "    label_paths += [os.path.join(label, filename) for filename in os.listdir(label) ]\n",
    "print(f\"Total labels: {len(label_paths)}\")\n",
    "\n",
    "rgb_paths = []\n",
    "for rgb in normalized_folders:\n",
    "    rgb_paths += [os.path.join(rgb, filename) for filename in os.listdir(rgb) ]\n",
    "print(f\"Total rgb: {len(rgb_paths)}\")\n",
    "\n",
    "# Normalizing Brightness and Contrast for Consistent Illumination and Color\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Select a random image and its corresponding label\n",
    "index = random.randint(0, len(rgb_paths) - 1)\n",
    "rgb_path = rgb_paths[index]\n",
    "label_path = label_paths[index]\n",
    "print(f\"{const.IMAGE_NAME}: {rgb_path}\")\n",
    "# Load the image and its corresponding label\n",
    "rgb_image = plt.imread(rgb_path)\n",
    "label_image = plt.imread(label_path)\n",
    "\n",
    "# Display the image and its corresponding label\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(rgb_image)\n",
    "ax[0].set_title(const.IMAGE_TITLE)\n",
    "ax[0].set_xlabel(f'{const.WIDTH_NAME}: {rgb_image.shape[1]} {const.PIXEL_NAME}')\n",
    "ax[0].set_ylabel(f'{const.HEIGHT_NAME}: {rgb_image.shape[0]} {const.PIXEL_NAME}')\n",
    "ax[1].imshow(label_image, cmap=const.CMAP_GRAY)\n",
    "ax[1].set_title(const.LABEL_TITLE)\n",
    "ax[1].set_xlabel(f' {const.WIDTH_NAME}: {label_image.shape[1]} {const.PIXEL_NAME}')\n",
    "ax[1].set_ylabel(f' {const.HEIGHT_NAME}: {label_image.shape[0]} {const.PIXEL_NAME}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide Data into Train , Test and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training (60%) and test (40%) sets\n",
    "train_rgb_paths, test_rgb_paths, train_label_paths, test_label_paths = train_test_split(rgb_paths, label_paths, test_size=const.TEST_SIZE, random_state=const.RANDOM_STATE)\n",
    "\n",
    "# Split the test set into two equal parts for evaluation and validation\n",
    "eval_rgb_paths, val_rgb_paths, eval_label_paths, val_label_paths = train_test_split(test_rgb_paths, test_label_paths, test_size=const.EVALUATION_SIZE, random_state=const.RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Total train: {len(train_rgb_paths)}\")\n",
    "print(f\"Total val: {len(val_rgb_paths)}\")\n",
    "print(f\"Total eval: {len(eval_rgb_paths)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Processing Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def load_labels(paths):\n",
    "    images = []\n",
    "    for path in paths:\n",
    "        with Image.open(path) as img:\n",
    "            img = np.array(img)\n",
    "            output_img = np.zeros(img.shape, dtype=np.uint8)  # Create a blank array for output image\n",
    "            output_img[np.all(img >= [100, 120, 100], axis=-1)] = [255, 255, 255]  # Assign white to almost white pixels\n",
    "            output_img[np.all(img < [100, 120, 100], axis=-1)] = [46, 101, 53]  # Assign the new color to all other pixels\n",
    "            # Assign white to any remaining black pixels\n",
    "            output_img[np.all(output_img == [0, 0, 0], axis=-1)] = [255, 255, 255]\n",
    "            images.append(output_img)\n",
    "\n",
    "    return np.array(images)\n",
    "\n",
    "# imagenes etiquetadas en formato grayscale\n",
    "\n",
    "def load_images(paths):\n",
    "    images = []\n",
    "    for path in paths:\n",
    "        img = cv2.imread(path)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the images and save them to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_path = path.make_path(ABSOLUTE_PATH, const.DATA_DIR, const.PROCESSED_DIR, const.TRAIN_DIR)\n",
    "data_val_path = path.make_path(ABSOLUTE_PATH, const.DATA_DIR, const.PROCESSED_DIR, const.VALIDATION_DIR)\n",
    "data_eval_path = path.make_path(ABSOLUTE_PATH, const.DATA_DIR, const.PROCESSED_DIR, const.EVALUATION_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.save(\"{}/{}\".format(data_train_path, const.TRAIN_RGB_NPY), load_images(train_rgb_paths))\n",
    "np.save(\"{}/{}\".format(data_train_path, const.TRAIN_LABEL_NPY), load_labels(train_label_paths))\n",
    "np.save(\"{}/{}\".format(data_val_path, const.VAL_RGB_NPY), load_images(val_rgb_paths))\n",
    "np.save(\"{}/{}\".format(data_val_path, const.VAL_LABEL_NPY), load_labels(val_label_paths))\n",
    "np.save(\"{}/{}\".format(data_eval_path, const.EVAL_RGB_NPY), load_images(eval_rgb_paths))\n",
    "np.save(\"{}/{}\".format(data_eval_path, const.EVAL_LABEL_NPY), load_labels(eval_label_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_rgb_images = np.load(\"{}/{}\".format(data_train_path, const.TRAIN_RGB_NPY))\n",
    "train_label_images = np.load(\"{}/{}\".format(data_train_path, const.TRAIN_LABEL_NPY))\n",
    "\n",
    "eval_rgb_images = np.load(\"{}/{}\".format(data_val_path, const.VAL_RGB_NPY))\n",
    "eval_label_images = np.load(\"{}/{}\".format(data_val_path, const.VAL_LABEL_NPY))\n",
    "\n",
    "val_rgb_images = np.load(\"{}/{}\".format(data_eval_path, const.EVAL_RGB_NPY))\n",
    "val_label_images = np.load(\"{}/{}\".format(data_eval_path, const.EVAL_LABEL_NPY))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-Score Normalization | $Z = \\frac{X - \\mu}{\\sigma}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_path = path.make_path(ABSOLUTE_PATH, const.DATA_DIR, const.PROCESSED_DIR, const.NORMALIZATION_DIR)\n",
    "mean = np.mean(train_rgb_images, axis=(0, 1, 2))  # Calculate the mean per channel\n",
    "std = np.std(train_rgb_images, axis=(0, 1, 2))  # Calculate the standard deviation per channel\n",
    "\n",
    "#save the mean and std as npy files\n",
    "np.save(\"{}/{}\".format(normalized_path, const.MEAN_NPY), mean)\n",
    "np.save(\"{}/{}\".format(normalized_path, const.STD_NPY), std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-Max Scaling Normalization | $X' = \\frac{X - X_{min}}{X_{max} - X_{min}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = np.min(train_rgb_images, axis=(0, 1, 2))  # Calculate the min per channel\n",
    "max_val = np.max(train_rgb_images, axis=(0, 1, 2))  # Calculate the max per channel\n",
    "\n",
    "#save the min and max as npy files\n",
    "np.save(\"{}/{}\".format(normalized_path, const.MIN_NPY), min_val)\n",
    "np.save(\"{}/{}\".format(normalized_path, const.MAX_NPY), max_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rendering Images to see the changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Genera 5 índices aleatorios\n",
    "random_indices = np.random.choice(len(train_rgb_images), 5, replace=False)\n",
    "\n",
    "fig, ax = plt.subplots(5, 2, figsize=(10, 20))\n",
    "for i, idx in enumerate(random_indices):\n",
    "    ax[i, 0].imshow(train_rgb_images[idx])\n",
    "    ax[i, 0].set_title('Imagen RGB')\n",
    "    ax[i, 1].imshow(train_label_images[idx])\n",
    "    ax[i, 1].set_title('Etiqueta')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "da0733af7d5e633716952d6f8ccf7a258aa98b5642ab14678a50d16c8d42da41"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
